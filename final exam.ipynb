{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP5olY8vv79AksegDQv7lQF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaypavuluri87/final-exam/blob/main/final%20exam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # Changed import statement\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # Changed import statement\n",
        "from tensorflow.keras.models import Sequential, load_model # Changed import statement\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM # Changed import statement\n",
        "from tensorflow.keras.utils import to_categorical # Changed import statement\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# 1. Load and preprocess the dataset\n",
        "# If the file is not in '/content/', replace 'Data (1).csv' with the correct path.\n",
        "# For example, if it's in the current directory:\n",
        "# data = pd.read_csv('Data (1).csv')\n",
        "data = pd.read_csv('/content/Data (1).csv') # Make sure the path is correct\n",
        "data = data[['text', 'sentiment']]\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))\n",
        "data['text'] = data['text'].str.replace('rt', ' ')\n",
        "# 2. Tokenization\n",
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "X = pad_sequences(X)\n",
        "\n",
        "# 3. Encode target\n",
        "labelencoder = LabelEncoder()\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment'])\n",
        "y = to_categorical(integer_encoded)\n",
        "\n",
        "# 4. Train/Test Split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# 5. Model creation function\n",
        "def create_model(units=196, dropout_rate=0.2):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=X.shape[1]))\n",
        "    model.add(LSTM(units, dropout=dropout_rate, recurrent_dropout=dropout_rate))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 6. Train and save the model\n",
        "model = create_model(units=196, dropout_rate=0.2)\n",
        "model.fit(X_train, Y_train, epochs=3, batch_size=32, verbose=2)\n",
        "model.save(\"sentiment_lstm_model.keras\")\n",
        "print(\"Model saved.\")\n",
        "\n",
        "# 7. Load and predict on new input\n",
        "model = load_model(\"sentiment_lstm_model.keras\")\n",
        "new_text = [\"A lot of good things are happening. We are respected again throughout the world, and that's a great thing .@realDonaldTrump\"]\n",
        "new_text = [re.sub('[^a-zA-Z0-9\\s]', '', x.lower().replace('rt', ' ')) for x in new_text]\n",
        "new_seq = tokenizer.texts_to_sequences(new_text)\n",
        "new_pad = pad_sequences(new_seq, maxlen=X.shape[1])\n",
        "pred = model.predict(new_pad)\n",
        "pred_class = labelencoder.inverse_transform([np.argmax(pred)])\n",
        "print(\"Predicted sentiment:\", pred_class[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXkjiAw3ZUM7",
        "outputId": "bfbb808d-7a5c-42bb-9569-f8ff38681167"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "291/291 - 37s - 128ms/step - accuracy: 0.6379 - loss: 0.8363\n",
            "Epoch 2/3\n",
            "291/291 - 34s - 117ms/step - accuracy: 0.7062 - loss: 0.6917\n",
            "Epoch 3/3\n",
            "291/291 - 41s - 140ms/step - accuracy: 0.7382 - loss: 0.6221\n",
            "Model saved.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step\n",
            "Predicted sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try different values:\n",
        "units_list = [128, 196]\n",
        "dropouts = [0.2, 0.3]\n",
        "batches = [32, 64]\n",
        "\n",
        "for units in units_list:\n",
        "    for dropout in dropouts:\n",
        "        for batch in batches:\n",
        "            print(f\"\\nTraining with units={units}, dropout={dropout}, batch={batch}\")\n",
        "            model = create_model(units=units, dropout_rate=dropout)\n",
        "            model.fit(X_train, Y_train, epochs=2, batch_size=batch, verbose=2)\n",
        "            loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "            print(f\"Validation Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asbggNYbaQdf",
        "outputId": "a4b4ea14-7218-4986-ad16-9df38a7acaa9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with units=128, dropout=0.2, batch=32\n",
            "Epoch 1/2\n",
            "291/291 - 29s - 100ms/step - accuracy: 0.6363 - loss: 0.8347\n",
            "Epoch 2/2\n",
            "291/291 - 25s - 86ms/step - accuracy: 0.7058 - loss: 0.6878\n",
            "Validation Accuracy: 0.6741\n",
            "\n",
            "Training with units=128, dropout=0.2, batch=64\n",
            "Epoch 1/2\n",
            "146/146 - 17s - 115ms/step - accuracy: 0.6321 - loss: 0.8488\n",
            "Epoch 2/2\n",
            "146/146 - 20s - 138ms/step - accuracy: 0.7005 - loss: 0.6983\n",
            "Validation Accuracy: 0.6697\n",
            "\n",
            "Training with units=128, dropout=0.3, batch=32\n",
            "Epoch 1/2\n",
            "291/291 - 29s - 99ms/step - accuracy: 0.6368 - loss: 0.8418\n",
            "Epoch 2/2\n",
            "291/291 - 25s - 87ms/step - accuracy: 0.7063 - loss: 0.6964\n",
            "Validation Accuracy: 0.6684\n",
            "\n",
            "Training with units=128, dropout=0.3, batch=64\n",
            "Epoch 1/2\n",
            "146/146 - 17s - 114ms/step - accuracy: 0.6267 - loss: 0.8630\n",
            "Epoch 2/2\n",
            "146/146 - 13s - 86ms/step - accuracy: 0.6892 - loss: 0.7147\n",
            "Validation Accuracy: 0.6765\n",
            "\n",
            "Training with units=196, dropout=0.2, batch=32\n",
            "Epoch 1/2\n",
            "291/291 - 29s - 101ms/step - accuracy: 0.6440 - loss: 0.8329\n",
            "Epoch 2/2\n",
            "291/291 - 25s - 87ms/step - accuracy: 0.7046 - loss: 0.6896\n",
            "Validation Accuracy: 0.6809\n",
            "\n",
            "Training with units=196, dropout=0.2, batch=64\n",
            "Epoch 1/2\n",
            "146/146 - 17s - 117ms/step - accuracy: 0.6347 - loss: 0.8475\n",
            "Epoch 2/2\n",
            "146/146 - 13s - 88ms/step - accuracy: 0.6985 - loss: 0.7031\n",
            "Validation Accuracy: 0.6695\n",
            "\n",
            "Training with units=196, dropout=0.3, batch=32\n",
            "Epoch 1/2\n",
            "291/291 - 28s - 96ms/step - accuracy: 0.6343 - loss: 0.8443\n",
            "Epoch 2/2\n",
            "291/291 - 25s - 85ms/step - accuracy: 0.7027 - loss: 0.6977\n",
            "Validation Accuracy: 0.6839\n",
            "\n",
            "Training with units=196, dropout=0.3, batch=64\n",
            "Epoch 1/2\n",
            "146/146 - 17s - 119ms/step - accuracy: 0.6268 - loss: 0.8636\n",
            "Epoch 2/2\n",
            "146/146 - 13s - 89ms/step - accuracy: 0.6975 - loss: 0.7093\n",
            "Validation Accuracy: 0.6723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"/content/Data (1).csv\")\n",
        "\n",
        "# Filter relevant and confident samples\n",
        "df_filtered = df[(df['relevant_yn'] == 'yes') & (df['sentiment_confidence'] > 0.6)]\n",
        "X = df_filtered['text']\n",
        "y = df_filtered['sentiment']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
        "    ('clf', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'clf__C': [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "# Apply GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = grid_search.predict(X_test)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save the best model\n",
        "joblib.dump(grid_search.best_estimator_, \"best_sentiment_model.pkl\")\n",
        "\n",
        "# Predict on example text\n",
        "example = [\"A lot of good things are happening. We are respected again throughout the world, and that's a great thing.\"]\n",
        "prediction = grid_search.predict(example)\n",
        "print(\"Prediction for example text:\", prediction[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKP_2EJwb8_9",
        "outputId": "e53565d1-25ba-444f-c5ce-05f33da3562c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.80      0.86      0.83      1577\n",
            "     Neutral       0.53      0.45      0.49       521\n",
            "    Positive       0.63      0.60      0.61       344\n",
            "\n",
            "    accuracy                           0.73      2442\n",
            "   macro avg       0.66      0.63      0.64      2442\n",
            "weighted avg       0.72      0.73      0.73      2442\n",
            "\n",
            "Prediction for example text: Positive\n"
          ]
        }
      ]
    }
  ]
}